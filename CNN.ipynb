{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9dd70c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# helper functions\n",
    "def show_min_max(array, i):\n",
    "  random_image = array[i]\n",
    "  print(random_image.min(), random_image.max())\n",
    "\n",
    "def plot_image(array, i, labels):\n",
    "  plt.imshow(np.squeeze(array[i]))\n",
    "  plt.title(\" Digit \" + str(labels[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n",
    "\n",
    "img_rows, img_cols = 28, 28  \n",
    "num_classes = 10\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "(train_images_backup, train_labels_backup), (test_images_backup, test_labels_backup) = mnist.load_data()\n",
    "print(train_images.shape) \n",
    "print(test_images.shape)\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0],  img_rows, img_cols, 1) \n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "plot_image(train_images, 100, train_labels)\n",
    "show_min_max(train_images, 100) \n",
    "\n",
    "train_images = train_images.astype('float32') \n",
    "test_images = test_images.astype('float32') \n",
    "train_images /= 255 \n",
    "test_images /= 255\n",
    "plot_image(train_images, 100, train_labels) \n",
    "show_min_max(train_images, 100)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes) \n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73673e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 11, 11, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 9, 9, 32)          18464     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2592)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                82976     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,586\n",
      "Trainable params: 120,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 36s 37ms/step - loss: 0.1610 - accuracy: 0.9492 - val_loss: 0.0667 - val_accuracy: 0.9798\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 36s 38ms/step - loss: 0.0510 - accuracy: 0.9844 - val_loss: 0.0432 - val_accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 34s 37ms/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 0.0265 - val_accuracy: 0.9914\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0260 - val_accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0279 - val_accuracy: 0.9907\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 38s 41ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0314 - val_accuracy: 0.9905\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 38s 40ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0295 - val_accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 35s 38ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.0277 - val_accuracy: 0.9923\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 36s 38ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0314 - val_accuracy: 0.9915\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 36s 39ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.0284 - val_accuracy: 0.9930\n",
      "313/313 - 1s - loss: 0.0284 - accuracy: 0.9930 - 1s/epoch - 4ms/step\n",
      "\n",
      "Test accuracy: 0.9929999709129333\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "epochs=10\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',  metrics=['accuracy']) \n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=64, epochs=epochs, validation_data=(test_images, test_labels), shuffle=True)\n",
    "\n",
    "test_loss, test_acc=model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d587c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30996748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
