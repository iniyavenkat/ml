{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9dd70c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "    # helper functions\n",
    "    def show_min_max(array, i):\n",
    "    random_image = array[i]\n",
    "    print(random_image.min(), random_image.max())\n",
    "\n",
    "    def plot_image(array, i, labels):\n",
    "    plt.imshow(np.squeeze(array[i]))\n",
    "    plt.title(\" Digit \" + str(labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "img_rows, img_cols = 28, 28  \n",
    "num_classes = 10\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "(train_images_backup, train_labels_backup), (test_images_backup, test_labels_backup) = mnist.load_data()\n",
    "print(train_images.shape) \n",
    "print(test_images.shape)\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0],  img_rows, img_cols, 1) \n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "plot_image(train_images, 100, train_labels)\n",
    "show_min_max(train_images, 100) \n",
    "\n",
    "train_images = train_images.astype('float32') \n",
    "test_images = test_images.astype('float32') \n",
    "train_images /= 255 \n",
    "test_images /= 255\n",
    "plot_image(train_images, 100, train_labels) \n",
    "show_min_max(train_images, 100)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes) \n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73673e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_24 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 25)                525       \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 30)                780       \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,315\n",
      "Trainable params: 17,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4380 - accuracy: 0.8703\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2308 - accuracy: 0.9329\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1875 - accuracy: 0.9443\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1630 - accuracy: 0.9513\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1477 - accuracy: 0.9560\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1360 - accuracy: 0.9593\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1235 - accuracy: 0.9625\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1154 - accuracy: 0.9642\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1075 - accuracy: 0.9670\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1015 - accuracy: 0.9678\n",
      "313/313 - 0s - loss: 0.1407 - accuracy: 0.9610 - 320ms/epoch - 1ms/step\n",
      "\n",
      "Test accuracy: 0.9610000252723694\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "epochs=10\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(20, activation='softplus'))\n",
    "model.add(Dense(25, activation='softplus'))\n",
    "model.add(Dense(30, activation='softplus'))\n",
    "model.add(Dense(10, activation='softplus'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=epochs, shuffle=True)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d587c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc987a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
